{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW scoring clarifications\n",
    "\n",
    "Once again, how do we score you home assignment.\n",
    "\n",
    "- You have to fill the google form for each question (e.g. 1, 2, 3, etc.) and each 'subtask' (e.g. 1.1, 1.3; 2.3, 2.2, etc.) **you asked for** in the google sheets.\n",
    "\n",
    "- If a question is not in the google sheet (e.g. question 13, 17), it **does not mean that they are optional**. They will be checked manually.\n",
    "\n",
    "- You have to submit filled `.ipynb` file (very last question in the google form).\n",
    "\n",
    "- `.ipynb` file must be **linearly executable** (`Kernel -> Restart & Run All -> No ERROR cells`). It is your task to make it so. ```If this condition is not satisfied, we will be forced to lower the grade.```\n",
    "\n",
    "- We do not grade the scores you obtain in part 7 with your models (you are free to use different feautres). However, not normalizing *numerical* features for linear regression, using the `price` as a feature (features, that are derived from price), not dealing with categorical features will be considered as mistakes.\n",
    "\n",
    "- You do not need to defend an assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each student has personal set of questions\n",
    "\n",
    "Google sheet with personal questions: https://docs.google.com/spreadsheets/d/1y9edy0BksXGO8BbN_hvsdylCpE-ly5b7hsUvI0EKGqE/edit?usp=sharing\n",
    "\n",
    "Every column corresponds to a single question, every row to a single student.\n",
    "\n",
    "For example, Abramov Denis need to report questions  1.1, 1.2, 1.3, 1.4, 2.1, 2.2, 3.1, 3.5 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submiting results\n",
    "\n",
    "Google form to submit your answers: https://docs.google.com/forms/d/e/1FAIpQLSfKWK7IRDd69L4GaoBIMhRJZmE58GM45hAS5d0-PRcafLICvw/viewform?usp=sharing&ouid=106266919004479425398\n",
    "\n",
    "Google form has fields for all questions, but you only need to answer **your** questions (from google sheet above).\n",
    "\n",
    "Use your **skoltech email**. Fill your first and last names with **exactly same spelling** as in canvas system.\n",
    "\n",
    "Almost all questions in google form will be checked automatically, so it is important to give them in the correct form, e.g.\n",
    "\n",
    "---\n",
    "\n",
    "Every question has an information about the type of the answer, e.g.\n",
    "\n",
    "> Observe top 10 observations (int)\n",
    "\n",
    "here your answer must be a single **integer** number.\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``float number``, then it must be provided with **3 decimals after the floating point**, e.g. 1.234\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``list of float or integer numbers or str``, then they should be reported in descending (alphabetical) order, without spacing, divided by a comma, e.g.:\n",
    "\n",
    "10.453,9.112,5.001,5.000 - **Right**\n",
    "\n",
    "10.453, 9.112, 5.001, 5.000 - **Wrong**\n",
    "\n",
    "\n",
    "If you are reporting a float value (or a list of float values) to a rule it must be provided with **3 decimals after the floating point**, e.g. 1.234\n",
    "\n",
    "0.51,0.0 - wrong\n",
    "\n",
    "0.5100,0.0000 - wrong\n",
    "\n",
    "0.510,0.000 - right\n",
    "\n",
    "In question Q1.3, where you need to answer the question, Which columns are associated... you need to give a list of multiple rows, then the rule in the explanation applies to them\n",
    "\n",
    "then they should be reported in alphabetical order, without spacing, divided by a comma(!)\n",
    "\n",
    "column_b, column_c, column_a - wrong\n",
    "\n",
    "column_a,column_b,column_c - right\n",
    "\n",
    "In special question Q5 you are deliberately asked to give your answer in alphabetical order, but remember: without spacing, divided by a comma(!)\n",
    "\n",
    "4,20,... - right\n",
    "\n",
    "4, 20, ... - wrong\n",
    "\n",
    "[4,20,...] - wrong\n",
    "\n",
    "20,4,.. - wrong\n",
    "\n",
    "---\n",
    "\n",
    "In problem Q6\n",
    "The answers must be in the order max,min,mean,std (without spacing, divided by a comma(!)).\n",
    "\n",
    "\n",
    "For questions Q18.1-Q18.2 str name of weekday good, but I think int number can be enough\n",
    "\n",
    "For int values\n",
    "8.0 - wrong\n",
    "8 - right\n",
    "\n",
    "Please don't google form answers - “look in the notebook, the answer is there”. That's not how it works) Some of the questions will be checked automatically any\n",
    " \n",
    "\n",
    "The question Q1.3  (# Q1.3 Which columns are associated with the condition of weather?) requires the answer of “WHICH” columns \n",
    "That is assuming a list with rows, not numbers\n",
    "\n",
    "---\n",
    "\n",
    "Part of the tasks do not have corresponding fields in the google form. They are **not optional** and they will be graded manually from your .ipynb file.\n",
    "\n",
    "---\n",
    "\n",
    "If you have any questions regarding this Home Assignment, ask them via telegram chat, topic 'HW1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fengSNSWl1X"
   },
   "source": [
    "# Assignment 1. Traffic volume prediction.\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this task you will be able to manipulate huge tabular data:\n",
    "1. Compute different column's statistics (min, max, mean, quantiles etc.);\n",
    "2. Select observations/features by condition/index;\n",
    "3. Create new non-linear combinations of the columns (feature engineering);\n",
    "4. Perform automated data cleaning;\n",
    "\n",
    "and more.\n",
    "\n",
    "---\n",
    "\n",
    "For those who are not familiar with `pandas` we recommend these (alternative) tutorials:\n",
    "\n",
    "1. Single notebook, covers basic pandas functionality (starting with renaming columns ending with using map, apply etc) ~ 30 short examples with links on videos https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb . Highly recommended for everyone. (about 1-3 hours to go through)\n",
    "\n",
    "2. https://github.com/guipsamora/pandas_exercises/ 11 topics covering all essential functionality with excersises (with solutions).\n",
    "\n",
    "This task will be an easy ride after these tutorials.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBv4L3BoWtY8"
   },
   "source": [
    "We are using a public dataset compiling weather information and traffic data continuously monitored in the Twin Cities, Minnesota from 2012 to 2018. The dataset page can be found [here](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume). We've slightly modified it so please download the dataset provided on Canvas.  \n",
    "\n",
    "You need to download `Metro_Interstate_Traffic_Volume_mod.csv` from Canvas and place it in the same directory as this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rYmsZ_BQWx6a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mp5vQW5Xtw5"
   },
   "source": [
    "# 1. Loading data\n",
    "\n",
    "As always in Data Science you are starting with making nice cup of tea (or coffee). Your next move is to load the data:\n",
    "\n",
    "- Start with loading `Metro_Interstate_Traffic_Volume_mod.csv` file using `pd.read_csv()` function.\n",
    "- You may also want to increase maximal displayed pandas columns: set `pd.options.display.max_columns` to 30\n",
    "- Print top 10 observations in the table. `.head()`\n",
    "- Print last 10 observations in the table. `.tail()`\n",
    "- Print all the data columns names using method `.columns`\n",
    "- Print data size (number of rows and columns). This is the `.shape` of the data.\n",
    "\n",
    "*Almost* every python has a `head` and a `tail` just as DataFrames do.\n",
    "\n",
    "If you are using Google Colab, you can upload the file in the cell below. If you are NOT using Colab, set COLAB_P in the cell below to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "KS_2J7IXX9ZS",
    "outputId": "6a5a75dd-4245-4992-8c2b-20275dceb5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place your file to the same directory as the notebook, then read your file with pd.read_csv()\n"
     ]
    }
   ],
   "source": [
    "COLAB_P = False\n",
    "if COLAB_P:\n",
    "    print(\"Upload your file, then read it with pd.read_csv()\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    fn = list(uploaded.keys())[0]\n",
    "    print(\"File is uploaded to \", fn)\n",
    "else:\n",
    "    print(\"Place your file to the same directory as the notebook, then read your file with pd.read_csv()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IMsqdgKrYugR"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"Metro_Interstate_Traffic_Volume_mod_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "H0P12NdQZPxw",
    "outputId": "dc794a4e-c50f-408e-a284-a130a70d2dda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>291.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>5181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>293.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>5584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>293.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>6015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>none</td>\n",
       "      <td>294.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>5791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>none</td>\n",
       "      <td>293.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 18:00:00</td>\n",
       "      <td>4770.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0    none  288.28      0.0      0.0        40.0       Clouds   \n",
       "1    none  289.36      0.0      0.0        75.0       Clouds   \n",
       "2    none  289.58      0.0      0.0        90.0       Clouds   \n",
       "3    none  290.13      0.0      0.0        90.0       Clouds   \n",
       "4    none  291.14      0.0      0.0        75.0       Clouds   \n",
       "5    none  291.72      0.0      0.0         1.0        Clear   \n",
       "6    none  293.17      0.0      0.0         1.0        Clear   \n",
       "7    none  293.86      0.0      0.0         1.0        Clear   \n",
       "8    none  294.14      0.0      0.0        20.0       Clouds   \n",
       "9    none  293.10      0.0      0.0        20.0       Clouds   \n",
       "\n",
       "  weather_description            date_time  traffic_volume  \n",
       "0    scattered clouds  2012-10-02 09:00:00          5545.0  \n",
       "1       broken clouds  2012-10-02 10:00:00          4516.0  \n",
       "2     overcast clouds  2012-10-02 11:00:00          4767.0  \n",
       "3     overcast clouds  2012-10-02 12:00:00          5026.0  \n",
       "4       broken clouds  2012-10-02 13:00:00          4918.0  \n",
       "5        sky is clear  2012-10-02 14:00:00          5181.0  \n",
       "6        sky is clear  2012-10-02 15:00:00          5584.0  \n",
       "7        sky is clear  2012-10-02 16:00:00          6015.0  \n",
       "8          few clouds  2012-10-02 17:00:00          5791.0  \n",
       "9          few clouds  2012-10-02 18:00:00          4770.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe top 10 observations (int)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "MXEj8wifdVjV",
    "outputId": "2c48f70b-b389-49bb-a9f3-3a506cbaa51f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48194</th>\n",
       "      <td>none</td>\n",
       "      <td>283.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>proximity shower rain</td>\n",
       "      <td>2018-09-30 15:00:00</td>\n",
       "      <td>4302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48195</th>\n",
       "      <td>none</td>\n",
       "      <td>283.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>light intensity drizzle</td>\n",
       "      <td>2018-09-30 15:00:00</td>\n",
       "      <td>4302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48196</th>\n",
       "      <td>none</td>\n",
       "      <td>284.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2018-09-30 16:00:00</td>\n",
       "      <td>4283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48197</th>\n",
       "      <td>none</td>\n",
       "      <td>284.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2018-09-30 17:00:00</td>\n",
       "      <td>4132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48198</th>\n",
       "      <td>none</td>\n",
       "      <td>284.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2018-09-30 18:00:00</td>\n",
       "      <td>3947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48199</th>\n",
       "      <td>none</td>\n",
       "      <td>283.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2018-09-30 19:00:00</td>\n",
       "      <td>3543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48200</th>\n",
       "      <td>none</td>\n",
       "      <td>282.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 20:00:00</td>\n",
       "      <td>2781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>none</td>\n",
       "      <td>282.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Thunderstorm</td>\n",
       "      <td>proximity thunderstorm</td>\n",
       "      <td>2018-09-30 21:00:00</td>\n",
       "      <td>2159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48202</th>\n",
       "      <td>none</td>\n",
       "      <td>282.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 22:00:00</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>none</td>\n",
       "      <td>282.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 23:00:00</td>\n",
       "      <td>954.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      holiday    temp  rain_1h  snow_1h  clouds_all  weather_main  \\\n",
       "48194    none  283.84     0.00      0.0        75.0          Rain   \n",
       "48195    none  283.84     0.00      0.0        75.0       Drizzle   \n",
       "48196    none  284.38     0.00      0.0        75.0          Rain   \n",
       "48197    none  284.79     0.00      0.0        75.0        Clouds   \n",
       "48198    none  284.20     0.25      0.0        75.0          Rain   \n",
       "48199    none  283.45     0.00      0.0        75.0        Clouds   \n",
       "48200    none  282.76     0.00      0.0        90.0        Clouds   \n",
       "48201    none  282.73     0.00      0.0        90.0  Thunderstorm   \n",
       "48202    none  282.09     0.00      0.0        90.0        Clouds   \n",
       "48203    none  282.12     0.00      0.0        90.0        Clouds   \n",
       "\n",
       "           weather_description            date_time  traffic_volume  \n",
       "48194    proximity shower rain  2018-09-30 15:00:00          4302.0  \n",
       "48195  light intensity drizzle  2018-09-30 15:00:00          4302.0  \n",
       "48196               light rain  2018-09-30 16:00:00          4283.0  \n",
       "48197            broken clouds  2018-09-30 17:00:00          4132.0  \n",
       "48198               light rain  2018-09-30 18:00:00          3947.0  \n",
       "48199            broken clouds  2018-09-30 19:00:00          3543.0  \n",
       "48200          overcast clouds  2018-09-30 20:00:00          2781.0  \n",
       "48201   proximity thunderstorm  2018-09-30 21:00:00          2159.0  \n",
       "48202          overcast clouds  2018-09-30 22:00:00          1450.0  \n",
       "48203          overcast clouds  2018-09-30 23:00:00           954.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe last 10 observations (int)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zui3i6ZOdo2D",
    "outputId": "afbc65c8-ee84-4325-d5c0-9ff307c78f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday, temp, rain_1h, snow_1h, clouds_all, weather_main, weather_description, date_time, traffic_volume\n"
     ]
    }
   ],
   "source": [
    "# Print all the columns/features names (int)\n",
    "print (*df.columns, sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.1 How many columns end with a vowel (aeiou)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns end with a vowel: 2\n"
     ]
    }
   ],
   "source": [
    "vowels = ('a', 'e', 'i', 'o', 'u')\n",
    "count = len([i for i in df.columns if i[-1] in vowels])\n",
    "print (f'Number of columns end with a vowel: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.2 How many columns start with a vowel (aeiou)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns start with a vowel: 0\n"
     ]
    }
   ],
   "source": [
    "vowels = ('a', 'e', 'i', 'o', 'u')\n",
    "count = len([i for i in df.columns if i[0] in vowels])\n",
    "print (f'Number of columns start with a vowel: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.3 Which columns are associated with the condition of weather?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns that are associated with the condition of weather: weather_description,weather_main\n"
     ]
    }
   ],
   "source": [
    "count = sorted([i for i in df.columns if 'weather' in i])\n",
    "count_s = \",\".join(count)\n",
    "print (f'Columns that are associated with the condition of weather: {count_s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.4 How many columns have `th` in their names?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwPaHlDhuklP",
    "outputId": "b49a1252-f5be-4b1c-be5c-d048af3375d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns that are associated with the condition of weather: 2\n"
     ]
    }
   ],
   "source": [
    "count = len ([i for i in df.columns if 'th' in i])\n",
    "print (f'Number of columns that are associated with the condition of weather: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.1 How many observations are in the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:  48187\n"
     ]
    }
   ],
   "source": [
    "print ('Number of observations: ', df.drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.2 How many features are in the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ka8e4hmZdqLp",
    "outputId": "fefb08cc-d966-465a-ef55-cb5410f50b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  9\n"
     ]
    }
   ],
   "source": [
    "print ('Number of features: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWqFpMWPdy3E"
   },
   "source": [
    "# 2. Basic data exploration\n",
    "\n",
    "Lets do some basics:\n",
    "\n",
    "`.count()` number of not NaN's in every column.\n",
    "    \n",
    "Is there any missing values in the data?     \n",
    "Count number of unique values in every column .nunique().    \n",
    "What does this tells you about the features, which are most likely categorical and which are most likely numerical?    \n",
    "Use pandas `.describe()` to display basic statistic about the data.   \n",
    "Use pandas `.value_counts()` to count number of unique values in a specific column.   \n",
    "Use pandas `.min()`, `.max()`, `.mean()`, `.std()` to display specific statistics about the data.    \n",
    "Use pandas `.dtypes` field to display data types in columns. \n",
    "Hint You could use `.sort_index()` or `.sort_values()` to sort the result of `.value_counts()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwlcBdvIwlfB",
    "outputId": "1471393c-97aa-437d-ce98-377d5d62556e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday                48204\n",
      "temp                   48203\n",
      "rain_1h                48203\n",
      "snow_1h                48204\n",
      "clouds_all             48201\n",
      "weather_main           48203\n",
      "weather_description    48201\n",
      "date_time              48204\n",
      "traffic_volume         48199\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display number of not NaN's in every column (int)\n",
    "not_Nans_columns = df.count()\n",
    "print(not_Nans_columns)\n",
    "# Explicit NA can be find by df.isna() method and equal to np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.1 How many explicit NA values are in the `clouds_all` column?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of explicit NA values in \"clouds_all\" column: 3\n"
     ]
    }
   ],
   "source": [
    "count = df['clouds_all'].isna().sum()\n",
    "print(f'Number of explicit NA values in \"clouds_all\" column: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.5 How many explicit NA values are in the `traffic_volume` column?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of explicit NA values in \"traffic_volume\" column: 5\n"
     ]
    }
   ],
   "source": [
    "count = df['traffic_volume'].isna().sum()\n",
    "print(f'Number of explicit NA values in \"traffic_volume\" column: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now drop rows with NaN with `.dropna`. Remeber to either reassign your dataframe or provide `inplace=True` argument.\n",
    "# The 'none' string is not considered NaN and should not be dropped \n",
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "bo6KibQ3x4Jw",
    "outputId": "55e2f0a4-7591-4829-dc61-25b645d56487"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.201366</td>\n",
       "      <td>0.334356</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>49.369267</td>\n",
       "      <td>3259.859079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.337406</td>\n",
       "      <td>44.795638</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>39.016127</td>\n",
       "      <td>1986.972809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>272.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1192.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>291.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>310.070000</td>\n",
       "      <td>9831.300000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               temp       rain_1h       snow_1h    clouds_all  traffic_volume\n",
       "count  48190.000000  48190.000000  48190.000000  48190.000000    48190.000000\n",
       "mean     281.201366      0.334356      0.000222     49.369267     3259.859079\n",
       "std       13.337406     44.795638      0.008169     39.016127     1986.972809\n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000\n",
       "25%      272.160000      0.000000      0.000000      1.000000     1192.250000\n",
       "50%      282.440000      0.000000      0.000000     64.000000     3380.000000\n",
       "75%      291.800000      0.000000      0.000000     90.000000     4933.000000\n",
       "max      310.070000   9831.300000      0.510000    100.000000     7280.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic data statistics using .describe()\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique values in every column (int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.2 How many unique values are in the `weather_main` column?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in the \"weather_main\" column: 11\n"
     ]
    }
   ],
   "source": [
    "count = df_clean['weather_main'].nunique()\n",
    "print (f'Number of unique values in the \"weather_main\" column: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.5 How many unique values are in the `rain_1h` column?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in the \"rain_1h\" column: 372\n"
     ]
    }
   ],
   "source": [
    "count = df_clean['rain_1h'].nunique()\n",
    "print (f'Number of unique values in the \"rain_1h\" column: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPJMcqYQyD9y",
    "outputId": "d1ba998f-0b2b-469d-c6f0-0304fcb5a3f9"
   },
   "outputs": [],
   "source": [
    "# Count frequency of the values in different columns (list of ints in this ascending(!) order)\n",
    "# You could select a column using same syntax as for selecting a key from a dictionary: `data[colname]`\n",
    "# numpy's `unique` function can be useful for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.1 For every unique `weather_main` value give its number of occurences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences for every uniqbe \"weather_main\" value: 4,20,912,1034,1359,1821,2876,5671,5950,13384,15159\n"
     ]
    }
   ],
   "source": [
    "freq = df_clean['weather_main'].value_counts(ascending=True)\n",
    "list_freq = list(freq)\n",
    "print(f'Number of occurences for every uniqbe \"weather_main\" value: ' + \",\".join(str(i) for i in list_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.2 For every unique `weather_description` value give its number of occurences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences for every uniqbe \"weather_description\" value: 1,2,2,3,4,6,6,11,13,13,15,18,20,37,52,54,63,64,125,136,293,467,616,651,673,912,1100,1359,1664,1726,1946,1955,3371,3458,4665,5081,5950,11658\n"
     ]
    }
   ],
   "source": [
    "freq = df_clean['weather_description'].value_counts(ascending=True)\n",
    "list_freq = list(freq)\n",
    "print(f'Number of occurences for every uniqbe \"weather_description\" value: ' + \",\".join(str(i) for i in list_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vIOZuv7yErp",
    "outputId": "11c3fdb7-d4bc-4ad2-f059-d4ac01492e2e"
   },
   "outputs": [],
   "source": [
    "# Display some column statistics (list of floats, rounded up to 3 digits, e.g. 1.234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.2 What are the max, min, mean and the std of the `clouds_all` column?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max, min, mean and the std of the \"clouds_all\" column: 100.000,0.000,49.369,39.016\n"
     ]
    }
   ],
   "source": [
    "lst = [df_clean['clouds_all'].max(), df_clean['clouds_all'].min(), df_clean['clouds_all'].mean(), df_clean['clouds_all'].std()]\n",
    "r_list = [f\"{i:.3f}\" for i in lst]\n",
    "print (f'Max, min, mean and the std of the \"clouds_all\" column: ' + \",\".join(str(i) for i in r_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.4 What are the max, min, mean and the std of the `rain_1h` column?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max, min, mean and the std of the \"rain_1h\" column: 9831.300,0.000,0.334,44.796\n"
     ]
    }
   ],
   "source": [
    "lst = [df_clean['rain_1h'].max(), df_clean['rain_1h'].min(), df_clean['rain_1h'].mean(), df_clean['rain_1h'].std()]\n",
    "r_list = [f\"{i:.3f}\" for i in lst]\n",
    "print (f'Max, min, mean and the std of the \"rain_1h\" column: ' + \",\".join(str(i) for i in r_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71Kx1GnoyG7v",
    "outputId": "4748f2d3-ca71-45e7-8438-728672463e43"
   },
   "outputs": [],
   "source": [
    "# Display data types of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.3 How many columns have `float64` data type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with float64 data type: 5\n"
     ]
    }
   ],
   "source": [
    "count = (df_clean.dtypes == 'float64').sum()\n",
    "print(f'Number of columns with float64 data type: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.4 What are the columns with dtype == `float64`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with float64 data type: clouds_all,rain_1h,snow_1h,temp,traffic_volume\n"
     ]
    }
   ],
   "source": [
    "count = [i for i in df_clean.columns if df_clean[i].dtypes == 'float64']\n",
    "s_count = sorted(count)\n",
    "print(f'Columns with float64 data type: ' + \",\".join(str(i) for i in s_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rrG2dQQe5yf"
   },
   "source": [
    "# 3. Data selection\n",
    "\n",
    "In pandas.DataFrame you could select\n",
    "\n",
    "  Row/s by position (integer number [0 .. number of rows - 1]) .iloc or by DataFrame.index .loc:   \n",
    "\n",
    "```\n",
    "  data.loc[0]  \n",
    "  data.loc[5:10]  \n",
    "  data.iloc[0]  \n",
    "  data.iloc[5:10]   \n",
    "```\n",
    "\n",
    "Though, this is probably the worst way to manipulate rows.   \n",
    "  Columns by name\n",
    "\n",
    "```\n",
    "  data[columname]\n",
    "```\n",
    "\n",
    "  Row/s and columns\n",
    "\n",
    "```\n",
    "  data.loc[10, columname]  \n",
    "  data.iloc[10, columname]  \n",
    "```\n",
    "\n",
    "Using boolean mask\n",
    "\n",
    "```\n",
    "  mask = data[columname] > value  \n",
    "  data[mask]  \n",
    "```\n",
    "\n",
    "You could combine multiple conditions using & or | (and, or)   \n",
    "\n",
    "```\n",
    "cond1 = data[columname1] > value1  \n",
    "cond2 = data[columname2] > value2  \n",
    "data[cond1 & cond2]  \n",
    "```\n",
    "\n",
    "Using queries .query():  \n",
    "\n",
    "```\n",
    "value = 5 \n",
    "data.query(\"columname > value\")  \n",
    "```\n",
    "\n",
    "You could combine multiple conditions using and, or  \n",
    "\n",
    "```\n",
    "data.query(\"(columname1 > value1) and (columname2 > value2)\")\n",
    "```\n",
    "\n",
    "and others. See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html for more examples.\n",
    "\n",
    "Remember to use different quotation marks \" or ' for columnname inside a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJnCqUx-0YRx",
    "outputId": "0be7619b-9aa3-417c-a1b0-eb4579164d28"
   },
   "outputs": [],
   "source": [
    "# Select rows by position(!) (int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.1 What is the temperature of the time slot with index 777?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature of the time slot with index 777: 278.780\n"
     ]
    }
   ],
   "source": [
    "temp = df_clean.iloc[776].temp\n",
    "print (f'Temperature of the time slot with index 777: {temp:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.2 What is the weather description of the time slot with index 999?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather description of the time slot with index 999: overcast clouds\n"
     ]
    }
   ],
   "source": [
    "weath = df_clean.iloc[998].weather_description\n",
    "print (f'Weather description of the time slot with index 999: {weath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv5jRoeU0aQG",
    "outputId": "635a0c74-7039-40cc-a391-5b31c8823419"
   },
   "outputs": [],
   "source": [
    "# Select rows by index(!) (int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.2 What is the weather description of the time slot on index 5695?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather description of the time slot on index 5695: overcast clouds\n"
     ]
    }
   ],
   "source": [
    "weath = df_clean.loc[5695].weather_description\n",
    "print (f'Weather description of the time slot on index 5695: {weath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.5 When was the time slot with index of 38 captured?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time slot with index 38: 2012-10-04 03:00:00\n"
     ]
    }
   ],
   "source": [
    "time = df_clean.loc[38].date_time\n",
    "print (f'Time slot with index 38: {time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZneqD6P0e5C",
    "outputId": "e0a1552e-7042-4ead-eb0a-75cf9a213ea5"
   },
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns (int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.4 How many time slots are foggy? (weather_main = Fog)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of foggy time slots: 912\n"
     ]
    }
   ],
   "source": [
    "fog = (df_clean['weather_main'] == 'Fog').sum()\n",
    "print(f'Number of foggy time slots: {fog}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.5 When was the last observed timeslot with weather_description \"heavy snow\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last observed time slot with heavy snow: 2018-04-15 18:00:00\n"
     ]
    }
   ],
   "source": [
    "time = df_clean[df_clean['weather_description'] == 'heavy snow']\n",
    "l_time_i = time.index[-1]\n",
    "l_time = df_clean.loc[l_time_i, 'date_time']\n",
    "print(f'Last observed time slot with heavy snow: {l_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.1 What is the traffic volume of November 20th 2016, at 20:00?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic volume of November 20th 2016, at 20:00: 2070.000\n"
     ]
    }
   ],
   "source": [
    "traffic = df_clean[df_clean['date_time'] == '2016-11-20 20:00:00']\n",
    "traffic_r = traffic['traffic_volume'].values[0]\n",
    "print (f'Traffic volume of November 20th 2016, at 20:00: {traffic_r:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.4 What is the `traffic_volume` of a thirty fourth sample with `clouds_all` == 90?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic volume of a thirty fourth sample with clouds_all == 90: 4329.000\n"
     ]
    }
   ],
   "source": [
    "cond1 = df_clean[df_clean['clouds_all'] == 90]\n",
    "cond2 = cond1.iloc[33]\n",
    "traffic = cond2['traffic_volume']\n",
    "print (f'Traffic volume of a thirty fourth sample with clouds_all == 90: {traffic:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.2 What is the traffic volume for 99-th time slot with cloud coverage 75 percent?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic volume of a 99-th time slot with cloud coverage 75 percent: 1437.000\n"
     ]
    }
   ],
   "source": [
    "cond1 = df_clean[df_clean['clouds_all'] == 75]\n",
    "cond2 = cond1.iloc[98]\n",
    "traffic = cond2['traffic_volume']\n",
    "print (f'Traffic volume of a 99-th time slot with cloud coverage 75 percent: {traffic:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.5 What is the temperature of 1337-th time slot with clear sky (clouds_all <= 20)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature of 1337-th time slot with clear sky: 276.630\n"
     ]
    }
   ],
   "source": [
    "cond1 = df_clean[df_clean['clouds_all'] <= 20]\n",
    "cond2 = cond1.iloc[1336]\n",
    "temp = cond2['temp']\n",
    "print (f'Temperature of 1337-th time slot with clear sky: {temp:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBLabnN2fAPc"
   },
   "source": [
    "# 4. Creating new columns\n",
    "\n",
    "Creating new column of pandas.DataFrame is as easy as:\n",
    "```\n",
    "data['new_awesome_column'] = [] \n",
    "```\n",
    "that's it. But such a column is relatively useless. Typically, you would compute something new based on existing data and save it in a new column. For example one might want to sum a number of existing columns:\n",
    "```\n",
    "data['sum'] = data[col1] + data[col2] + ...\n",
    "```\n",
    "Pandas also provides another powerfull tool: .apply, .map(), .applymap() methods (they are kinda the same, but not quite). https://stackoverflow.com/questions/19798153/difference-between-map-applymap-and-apply-methods-in-pandas . They allow you to apply some function to every value in the column/s (row-wise) or row (column-wise) or cell (element-wise). For example, same computations of sum using .apply():\n",
    "```\n",
    "data['sum'] = data[[col1, col2, col3]].apply(sum, axis=1)\n",
    "```\n",
    "you are not restricted to existent functions, .apply() accepts any function (including lambda functions):\n",
    "```\n",
    "data['sum'] = data[[col1, col2, col3]].apply(lambda x: x[0]+x[1]+x[2], axis=1)\n",
    "```\n",
    "or ordinary python function (if this it should have complex behaviour):\n",
    "```\n",
    "def _sum(x):\n",
    "    total = 0\n",
    "    for elem in x:\n",
    "        total += elem\n",
    "    return total\n",
    "\n",
    "data['sum'] = data[[col1, col2, col3]].apply(_sum, axis=1) \n",
    "```\n",
    "Many pandas methods has axis parameter axis=0 refers to rows, axis=1 refers to columns.\n",
    "\n",
    "Warning. You should never use for loops to sum numerical elements from the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "nxbj9Po2Le18"
   },
   "outputs": [],
   "source": [
    "# Create new columns using the old ones (new column in your DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.1 Create a `temp_in_celcius` column from the existing `temp` (kelvin) using any method above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.copy()\n",
    "df_clean['temp_in_celsius'] = df_clean['temp'] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.2 Create a new bool column `hot` which indicates whether the time slot was hot (temp > 300)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['hot'] = df_clean['temp'] > 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.3 Create a new bool column `rainy_and_cloudy` which indicates whether it was rainy (>0.1) AND cloudy (>50)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['rainy_and_cloudy'] = (df_clean['rain_1h'] > 0.1) & (df_clean['clouds_all'] > 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.4 Create a new bool column `is_holiday` which indicates whether the day of the time slot falls on any holiday**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['is_holiday'] = df_clean['holiday'] != 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.5 Create a new column `traffic_cat` by splitting a `traffic_volume` into 5 ([1..5]) distinct intervals: 0 <= x <=20%, 20% < x <= 40%, ... 80% < x <= 100% percentiles. You could use `.quantile()` to compute percentiles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_clean.traffic_volume <= df_clean.traffic_volume.quantile(0.2))\n",
    "df_clean.loc[mask, 'traffic_cat'] = 1\n",
    "mask = (df_clean.traffic_volume.quantile(0.2) < df_clean.traffic_volume) & (df_clean.traffic_volume <= df_clean.traffic_volume.quantile(0.4)) \n",
    "df_clean.loc[mask, 'traffic_cat'] = 2\n",
    "mask = (df_clean.traffic_volume.quantile(0.4) < df_clean.traffic_volume) & (df_clean.traffic_volume <= df_clean.traffic_volume.quantile(0.6)) \n",
    "df_clean.loc[mask, 'traffic_cat'] = 3\n",
    "mask = (df_clean.traffic_volume.quantile(0.6) < df_clean.traffic_volume) & (df_clean.traffic_volume <= df_clean.traffic_volume.quantile(0.8))\n",
    "df_clean.loc[mask, 'traffic_cat'] = 4\n",
    "mask = (df_clean.traffic_volume.quantile(0.8) < df_clean.traffic_volume)\n",
    "df_clean.loc[mask, 'traffic_cat'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm4Ve-s70h73",
    "outputId": "d68d003c-151e-4803-9823-5c8d1686fff3"
   },
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns (int).\n",
    "# For working with dates, define helper functions that operate on the date_time string.\n",
    "# (transform dates in datetime format in Q14.x and Q15.x is forbidden!, work with date as the string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.2 How many rainy time slots (rain_1h > 0.1) that were captured in the fall (all falls, not in only ine year), with traffic volume more than 2000?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rainy time slots in fall with traffic volume> 2000: 589\n"
     ]
    }
   ],
   "source": [
    "def fall(date):\n",
    "    month = date[5:7]\n",
    "    return month in ['09', '10', '11']\n",
    "\n",
    "filt = df_clean[(df_clean['rain_1h'] > 0.1) & (df_clean['traffic_volume'] > 2000) & df_clean['date_time'].apply(fall)]\n",
    "print(f'Number of rainy time slots in fall with traffic volume> 2000: {filt.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.4 What is the minimum traffic volume of time slots captured on March 8th (all years), that was warmer than 290?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum traffic volume on March 8th when temp > 290: 4780.000\n"
     ]
    }
   ],
   "source": [
    "def march(date):\n",
    "    month = date[5:7]\n",
    "    day = date [8:10]\n",
    "    return month == '03' and day == '08'\n",
    "\n",
    "filt = df_clean[(df_clean['temp'] > 290) & df_clean['date_time'].apply(march)]\n",
    "print(f'Minimum traffic volume on March 8th when temp > 290: {filt['traffic_volume'].min():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTVitIYf0ib3",
    "outputId": "1300c6b6-032e-4497-ef1a-7b3c8497bf09"
   },
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns and compute simple statistics (float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.1 What was the average temperature of time slots with main weather \"Haze\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature of time slots with main weather \"Haze\": 275.805\n"
     ]
    }
   ],
   "source": [
    "av = df_clean[df_clean['weather_main'] == 'Haze']\n",
    "print(f'Average temperature of time slots with main weather \"Haze\": {av['temp'].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.2 What was the traffic volume of the coldest time slot of the year 2016?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic volume of the coldest time slot of the year 2016: 1462.000\n"
     ]
    }
   ],
   "source": [
    "def year(date):\n",
    "    y = date[0:4]\n",
    "    return y == '2016' \n",
    "year_df = df_clean[df_clean['date_time'].apply(year)]\n",
    "mind = year_df['temp'].idxmin()\n",
    "traffic = year_df.loc[mind, 'traffic_volume']\n",
    "print (f'Traffic volume of the coldest time slot of the year 2016: {traffic:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mask or .query syntax select rows/columns (float)\n",
    "# Remeber: string 'none' is not a holiday but also not equal to None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fzig1HmlL4rq",
    "outputId": "9ebe4adf-0811-4acc-85e9-7907180880a4"
   },
   "source": [
    "**Q16.1 What is the average temperature in celcius of the time slots with rainy_and_coudy=True?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature in celsius with rainy_and_coudy=True: 13.585\n"
     ]
    }
   ],
   "source": [
    "av = df_clean[df_clean['rainy_and_cloudy'] == True]['temp_in_celsius'].mean()\n",
    "print(f'Average temperature in celsius with rainy_and_coudy=True: {av:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.2 What is the average traffic volume on holidays?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average traffic volume on holidays: 865.443\n"
     ]
    }
   ],
   "source": [
    "av = df_clean[df_clean['holiday'] != 'none']['traffic_volume'].mean()\n",
    "print(f'Average traffic volume on holidays: {av:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.3 What is the average traffic volume on non-holidays?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average traffic volume on non-holidays: 3262.894\n"
     ]
    }
   ],
   "source": [
    "av = df_clean[df_clean['holiday'] == 'none']['traffic_volume'].mean()\n",
    "print(f'Average traffic volume on non-holidays: {av:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.4 What is the average traffic volume in the highest quantile?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average traffic volume in the highest quantile: 5870.913\n"
     ]
    }
   ],
   "source": [
    "av = df_clean[df_clean['traffic_cat'] == 5]['traffic_volume'].mean()\n",
    "print(f'Average traffic volume in the highest quantile: {av:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.5 What is the average traffic volume in the lowest quantile?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average traffic volume in the lowest quantile: 485.554\n"
     ]
    }
   ],
   "source": [
    "av = df_clean[df_clean['traffic_cat'] == 1]['traffic_volume'].mean()\n",
    "print(f'Average traffic volume in the lowest quantile: {av:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezvSnhPRfFXM"
   },
   "source": [
    "# 5. Basic date processing\n",
    "\n",
    "You figure out that column date is to harsh for you, so you decided to convert it to a more plausible format:\n",
    "\n",
    "- Use pandas method to_datetime() to convert the date to a good format.\n",
    "- Extract year, month, day and weekday from your new date column. Save them to separate columns.\n",
    "- How many columns has your data now?\n",
    "- Drop column date, remember to set inplace parameter to True.\n",
    "\n",
    "Hint: for datetime formatted date you could extract the year as follow:\n",
    "```\n",
    "data.date.dt.year\n",
    "```\n",
    "Very often date could be a ridiculously rich feature, sometimes it is holidays that matters, sometimes weekends, sometimes some special days like black friday.\n",
    "\n",
    "Learn how to work with date in Python!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "ZghL5CmKTBZc"
   },
   "outputs": [],
   "source": [
    "# Create new columns based on `Captured` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17.1 Convert date to datetime format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['date_time'] = pd.to_datetime(df_clean['date_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17.4 Extract and store day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['day'] = df_clean['date_time'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU_wYcyETK9T",
    "outputId": "4869f3a1-0740-4830-e014-70e1da8ba8e0"
   },
   "outputs": [],
   "source": [
    "# Find some date related information from the data\n",
    "# Weekday is a name, string, not index (\"Monday\"-like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18.4 What is the average traffic volume in the time period between 15-19 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average traffic volume between 15 and 19 hours: 4749.296\n"
     ]
    }
   ],
   "source": [
    "traffic = df_clean[(df_clean['date_time'].dt.hour >= 15) & (df_clean['date_time'].dt.hour <= 19)]\n",
    "print(f'Average traffic volume between 15 and 19 hours: {traffic['traffic_volume'].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18.5 What is the average traffic volume on World Bicycle Day (June 3)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average traffic volume on World Bicycle Day (June 3): 3445.976\n"
     ]
    }
   ],
   "source": [
    "traffic = df_clean[(df_clean['date_time'].dt.month == 6) & (df_clean['date_time'].dt.day == 3)]\n",
    "print(f'Average traffic volume on World Bicycle Day (June 3): {traffic['traffic_volume'].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LrPCPd0fRYz"
   },
   "source": [
    "# 6. Groupby\n",
    "\n",
    "from the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "- Splitting the data into groups based on some criteria.\n",
    "- Applying a function to each group independently.\n",
    "- Combining the results into a data structure.\n",
    "\n",
    "`.groupby()` is one of the most powerfull tool for feature engineering. Very often it is used to group object with the same categorical characteristics and compute some statistics (e.g. mean, max, etc.) of a their numerical characteric.\n",
    "\n",
    "Instead of computing average traffic volume with for each month you could compute average traffic volumes for every month in a single command:\n",
    "```\n",
    "data.groupby('month')['traffic_volume'].mean()\n",
    "```\n",
    "You could also make multi-column groups:\n",
    "```\n",
    "data.groupby(['weekday','month'])['traffic_volume'].min()\n",
    "```\n",
    "next, you could compute multiple aggregation functions:\n",
    "```\n",
    "data.groupby(['weekday','month'])['traffic_volume'].agg([min, max])\n",
    "```\n",
    "instead of using built-in functions you could compute custom functions using apply:\n",
    "```\n",
    "import numpy as np\n",
    "data.groupby(['weekday','month'])['traffic_volume'].apply(lambda x: np.quantile(x, .5))\n",
    "```\n",
    "and the coolest thing now is that you can map the results of groupby back on your DataFrame!\n",
    "```\n",
    "gp = data.groupby(['month'])['traffic_volume'].median()\n",
    "data['gp_feature'] = data['month'].map(gp)\n",
    "```\n",
    "Now, if some timeslot has month == 2, its gp_feature will be equal to the median traffic volume amongst all observations in February\n",
    "\n",
    "Read more examples in the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "nRmmkfIVXp5K"
   },
   "outputs": [],
   "source": [
    "# Create some groupby features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19.1 `traffic_by_year` groupby `year` and compute median traffic volume.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2012    3225.0\n",
      "2013    3344.0\n",
      "2014    3316.0\n",
      "2015    3368.0\n",
      "2016    3258.5\n",
      "2017    3530.0\n",
      "2018    3400.0\n",
      "Name: traffic_volume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_clean['year'] = df_clean['date_time'].dt.year\n",
    "traffic_by_year = df_clean.groupby(df_clean['year'])['traffic_volume'].median()\n",
    "df_clean['traffic_by_year'] = df_clean['year'].map(traffic_by_year)\n",
    "print(traffic_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19.2 `traffic_by_weekday` groupby `weekday` and compute median traffic volume.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekday\n",
      "Friday       4336.5\n",
      "Monday       3619.0\n",
      "Saturday     3003.0\n",
      "Sunday       2260.0\n",
      "Thursday     4280.0\n",
      "Tuesday      4070.0\n",
      "Wednesday    4315.0\n",
      "Name: traffic_volume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_clean['weekday'] = df_clean['date_time'].dt.day_name()\n",
    "traffic_by_weekday = df_clean.groupby(df_clean['weekday'])['traffic_volume'].median()\n",
    "df_clean['traffic_by_weekday'] = df_clean['weekday'].map(traffic_by_weekday)\n",
    "print(traffic_by_weekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19.3 `temperature_by_traffic` groupby `traffic_cat` and compute average temperature in celsius.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_cat\n",
      "1.0    5.445774\n",
      "2.0    6.031004\n",
      "3.0    9.244710\n",
      "4.0    9.797489\n",
      "5.0    9.740191\n",
      "Name: temp_in_celsius, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "temperature_by_traffic = df_clean.groupby(df_clean['traffic_cat'])['temp_in_celsius'].mean()\n",
    "df_clean['temperature_by_traffic'] = df_clean['traffic_cat'].map(temperature_by_traffic)\n",
    "print(temperature_by_traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y3IX6U1fOVI"
   },
   "source": [
    "# 7. Building a regression model\n",
    "\n",
    "- **You do not need to normalize data for tree models, and for linear/knn models this step is essential**.\n",
    "- Remember, that not all of the features in the table are numeric, some of them might be viewed as categorical.\n",
    "- You may create or drop any features you want - try to only keep features which you think will be relevant to the prediction of traffic volume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q20 Separate your data into inputs and targets, keeping only relevant inputs. Drop any features computed from the output eg. `traffic_cat`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "AwdbUu2wYKpB"
   },
   "outputs": [],
   "source": [
    "df_clean['is_weekend'] = df_clean['date_time'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "df_clean['month'] = df_clean['date_time'].dt.month\n",
    "df_clean['hour'] = df_clean['date_time'].dt.hour\n",
    "Y = df_clean[\"traffic_volume\"].values\n",
    "good_columns = ['temp_in_celsius', 'rain_1h', 'snow_1h', 'clouds_all', \n",
    "                'is_weekend', 'is_holiday', 'month', 'hour']\n",
    "Xdf = df_clean[good_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_in_celsius</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48199</th>\n",
       "      <td>10.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48200</th>\n",
       "      <td>9.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>9.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48202</th>\n",
       "      <td>8.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>8.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48190 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp_in_celsius  rain_1h  snow_1h  clouds_all  is_weekend  is_holiday  \\\n",
       "0                15.13      0.0      0.0        40.0           0       False   \n",
       "1                16.21      0.0      0.0        75.0           0       False   \n",
       "2                16.43      0.0      0.0        90.0           0       False   \n",
       "3                16.98      0.0      0.0        90.0           0       False   \n",
       "4                17.99      0.0      0.0        75.0           0       False   \n",
       "...                ...      ...      ...         ...         ...         ...   \n",
       "48199            10.30      0.0      0.0        75.0           1       False   \n",
       "48200             9.61      0.0      0.0        90.0           1       False   \n",
       "48201             9.58      0.0      0.0        90.0           1       False   \n",
       "48202             8.94      0.0      0.0        90.0           1       False   \n",
       "48203             8.97      0.0      0.0        90.0           1       False   \n",
       "\n",
       "       month  hour  \n",
       "0         10     9  \n",
       "1         10    10  \n",
       "2         10    11  \n",
       "3         10    12  \n",
       "4         10    13  \n",
       "...      ...   ...  \n",
       "48199      9    19  \n",
       "48200      9    20  \n",
       "48201      9    21  \n",
       "48202      9    22  \n",
       "48203      9    23  \n",
       "\n",
       "[48190 rows x 8 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5545., 4516., 4767., ..., 2159., 1450.,  954.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to split our data into train and test sets. Generally a random split is used, but one needs to be very careful with time series data - we need to make sure train and test data don't contain mixed adjacent time slots. In general with time series, it is recommended not to predict values from the past using input information from the future (although the applicability of this rule in our case is debatable), so we'll use sklearn's [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) class here. TimeSeriesSplit splits data into a number of folds, then only provides data from past folds to train a model tested on the currently considered fold. So if we split our data into five parts, we'll get four folds:\n",
    "\n",
    "1. Train on [0], test on [1]\n",
    "2. Train on [0,1], test on [2]\n",
    "3. Train on [0, 1, 2], test on [3]\n",
    "4. Train on [0, 1, 2, 3], test on [4]\n",
    "\n",
    "For the following tasks, you are required to use train and test indices from the last fold provided by TimeSeriesSplit with `n_splits` = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['is_weekend', 'is_holiday']\n",
    "num_columns = ['temp_in_celsius', 'rain_1h', 'snow_1h', 'clouds_all', 'hour', 'month'] #i understand that probably it is incorrect to put hour and month in numerical columns but i could not come with other solution :(\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_columns),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_columns)\n",
    "    ])\n",
    "X_processed = preprocessor.fit_transform(Xdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q21 Split your data into train and test parts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdLqDhuCYO1Z",
    "outputId": "99703cb2-7dc5-4987-cd29-7f1a149a2b57"
   },
   "outputs": [],
   "source": [
    "# How many records (rows) do you have in train and test tables? (list of int)?\n",
    "# Use sklearn.model_selection.TimeSeriesSplit with n_splits=5\n",
    "# in google forms report two ints: n_rows_train,n_rows_test\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 40159, Test samples: 8031\n"
     ]
    }
   ],
   "source": [
    "t = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in t.split(X_processed):\n",
    "    X_train, X_test = X_processed[train_index], X_processed[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53074094, -0.00746411, -0.0272323 , ...,  1.0274999 ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.61171705, -0.00746411, -0.0272323 , ...,  1.0274999 ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.62821218, -0.00746411, -0.0272323 , ...,  1.0274999 ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.54089774, -0.00746411, -0.0272323 , ...,  1.61562252,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.53265018, -0.00746411, -0.0272323 , ...,  1.61562252,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.54164752, -0.00746411, -0.0272323 , ...,  1.61562252,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictive regression model of a traffic volume.\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22.1 Use linear regression with l2 regularization (Ridge regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Ridge()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_ridge = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22.2 Use decision tree regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "destree = DecisionTreeRegressor()\n",
    "destree.fit(X_train, y_train)\n",
    "y_pred_tree = destree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqubzK5rYQA9",
    "outputId": "d9853eb1-2a3c-4eb2-e01a-aaceeb6d5b96"
   },
   "source": [
    "**Q22.3 Use k nearest neighbours regression**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search to select optimal hyperparamters of your models. \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q23.1 Alpha for a ridge regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100.0}\n"
     ]
    }
   ],
   "source": [
    "param = {'alpha': [10**x for x in np.linspace(0.1, 2.0, 50)]}\n",
    "ridge_gs = GridSearchCV(Ridge(), param)\n",
    "ridge_gs.fit(X_train, y_train)\n",
    "ridge_pred = ridge_gs.predict(X_test)\n",
    "print(ridge_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q23.2 Depth for the tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth': range(1, 20)}  \n",
    "dtree_gs = GridSearchCV(DecisionTreeRegressor(), param)\n",
    "dtree_gs.fit(X_train, y_train)\n",
    "dtree_pred = dtree_gs.predict(X_test)\n",
    "print(dtree_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q23.3 Number of neighbours for the knn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 12}\n"
     ]
    }
   ],
   "source": [
    "param = {'n_neighbors': range(1, 15)}\n",
    "knn_gs = GridSearchCV(KNeighborsRegressor(), param)\n",
    "knn_gs.fit(X_train, y_train)\n",
    "knn_pred = knn_gs.predict(X_test)\n",
    "print(knn_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVihHjlpYTrB",
    "outputId": "755e3cb5-acf6-4022-88a8-188cba883bef"
   },
   "outputs": [],
   "source": [
    "# Compute train and test mean squared error for your best models (list of float).\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q24.1 Train, test MSE using linear regression with l2 regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3233516.760,3167718.275\n"
     ]
    }
   ],
   "source": [
    "ridge_reg = Ridge(alpha=100)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "ridge_train_mse = mean_squared_error(y_train, reg.predict(X_train))\n",
    "ridge_test_mse = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(f'{ridge_train_mse:.3f},{ridge_test_mse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q24.2 Train, test MSE using decision tree regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289277.310,565422.343\n"
     ]
    }
   ],
   "source": [
    "destree = DecisionTreeRegressor(max_depth=7) \n",
    "destree.fit(X_train, y_train)\n",
    "tree_train_mse = mean_squared_error(y_train, destree.predict(X_train))\n",
    "tree_test_mse = mean_squared_error(y_test, y_pred_tree)\n",
    "print(f'{tree_train_mse:.3f},{tree_test_mse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q24.3 Train, test MSE using k nearest neighbours regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262950.248,413172.105\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=12)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_train_mse = mean_squared_error(y_train, knn.predict(X_train))\n",
    "knn_test_mse = mean_squared_error(y_test, y_pred_knn)\n",
    "print(f'{knn_train_mse:.3f},{knn_test_mse:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqwSIwVmYVZ6",
    "outputId": "c8bc2903-7def-4076-b7ba-b13cd2235b60"
   },
   "outputs": [],
   "source": [
    "# Compute train and test R^2 for your best models (list of float).\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q25.1 Train, test R^2 using linear regression with l2 regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.184,0.183\n"
     ]
    }
   ],
   "source": [
    "ridge_train_r2 = r2_score(y_train, reg.predict(X_train))\n",
    "ridge_test_r2 = r2_score(y_test, y_pred_ridge)\n",
    "print(f'{ridge_train_r2:.3f},{ridge_test_r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q25.2 Train, test R^2 using decision tree regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927,0.854\n"
     ]
    }
   ],
   "source": [
    "tree_train_r2 = r2_score(y_train, destree.predict(X_train))\n",
    "tree_test_r2 = r2_score(y_test, y_pred_tree)\n",
    "print(f'{tree_train_r2:.3f},{tree_test_r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q25.3 Train, test R^2 using k nearest neighbours regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934,0.893\n"
     ]
    }
   ],
   "source": [
    "knn_train_r2 = r2_score(y_train, knn.predict(X_train))\n",
    "knn_test_r2 = r2_score(y_test, y_pred_knn)\n",
    "print(f'{knn_train_r2:.3f},{knn_test_r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "qO3zWCyHYXQo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clouds_all', 'temp_in_celsius', 'hour', 'is_weekend', 'month']\n"
     ]
    }
   ],
   "source": [
    "# Q26 Which features have largest (by absolute value) weight in your linear model (top 5 features)? (list of str).\n",
    "print(list(Xdf.columns[np.argsort(np.abs(ridge_reg.coef_))[-5::]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G_LlOHofTJp"
   },
   "source": [
    "# Make sure your .ipynb is linearly executable     \n",
    "# Kernel -> Restart & Run All -> No ERROR cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q27 Save your .ipynb file: FirstName_SecondName_HA1.ipynb, you will be asked to upload it into the google form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
